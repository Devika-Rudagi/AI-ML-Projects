{"cells":[{"cell_type":"markdown","id":"40171432","metadata":{"id":"40171432"},"source":["# ðŸŽ¥ CNN-Encoder + LSTM-Decoder for Video Frame Prediction\n","This Colab-ready notebook implements a CNN encoder + LSTM decoder model in TensorFlow/Keras to predict future frames from an input video sequence. The Moving MNIST dataset is used as a sample.\n","\n","**Architecture:**\n","- CNN Encoder: Extracts spatial features from each input frame.\n","- LSTM Decoder: Learns temporal dynamics across frames.\n","- Output: Predicts the next frame(s) in the sequence."]},{"cell_type":"code","execution_count":1,"id":"b823a72d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b823a72d","executionInfo":{"status":"ok","timestamp":1753147362596,"user_tz":420,"elapsed":15844,"user":{"displayName":"Devika Rudagi","userId":"17017947672779449369"}},"outputId":"8798008a-dd9d-492c-bc5d-21efd241daa1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install tensorflow matplotlib scipy"]},{"cell_type":"code","execution_count":2,"id":"70a1f6bb","metadata":{"id":"70a1f6bb","executionInfo":{"status":"ok","timestamp":1753147376774,"user_tz":420,"elapsed":7210,"user":{"displayName":"Devika Rudagi","userId":"17017947672779449369"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers, models, Input\n","from tensorflow.keras.datasets import mnist\n","from scipy.ndimage import zoom"]},{"cell_type":"code","execution_count":5,"id":"8fd5bd1d","metadata":{"id":"8fd5bd1d","executionInfo":{"status":"ok","timestamp":1753147405532,"user_tz":420,"elapsed":12,"user":{"displayName":"Devika Rudagi","userId":"17017947672779449369"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers, models, Input\n","from tensorflow.keras.datasets import mnist\n","from scipy.ndimage import zoom\n","\n","def generate_moving_mnist(seq_length=10, image_size=64):\n","    (x_train, _), _ = mnist.load_data()\n","    img = x_train[np.random.choice(len(x_train))]\n","    # Apply zoom to the image before using it\n","    img = zoom(img, (image_size / 28, image_size / 28))\n","    sequence = []\n","    # Starting position for the image within the larger frame\n","    x, y = np.random.randint(0, image_size - img.shape[0], size=2)\n","    dx, dy = np.random.choice([-2, 2], size=2)\n","\n","    for _ in range(seq_length):\n","        frame = np.zeros((image_size, image_size), dtype=np.float32)\n","        # Use the zoomed image's shape for slicing\n","        frame[x:x+img.shape[0], y:y+img.shape[1]] = img / 255.0\n","        sequence.append(frame)\n","        x += dx\n","        y += dy\n","        # Use the zoomed image's shape for boundary checks\n","        if x < 0 or x > image_size - img.shape[0]: dx *= -1\n","        if y < 0 or y > image_size - img.shape[1]: dy *= -1\n","\n","    return np.array(sequence)"]},{"cell_type":"code","execution_count":6,"id":"2628ce24","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"2628ce24","executionInfo":{"status":"error","timestamp":1753147410158,"user_tz":420,"elapsed":421,"user":{"displayName":"Devika Rudagi","userId":"17017947672779449369"}},"outputId":"bac24a4c-4c2c-49bb-c78f-e67e883b40a1"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"high <= 0","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-6-3940512451.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_moving_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (10, 64, 64, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Input: first 5 frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Target: next 5 frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-5-1556812613.py\u001b[0m in \u001b[0;36mgenerate_moving_mnist\u001b[0;34m(seq_length, image_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Starting position for the image within the larger frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n","\u001b[0;32mnumpy/random/_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: high <= 0"]}],"source":["sequence = generate_moving_mnist(10)\n","sequence = np.expand_dims(sequence, -1)  # (10, 64, 64, 1)\n","\n","X_seq = sequence[:5]  # Input: first 5 frames\n","y_seq = sequence[5:]  # Target: next 5 frames\n","\n","# Normalize and expand dims for batch training\n","X_seq = X_seq[np.newaxis, ...]  # (1, 5, 64, 64, 1)\n","y_seq = y_seq[np.newaxis, ...]"]},{"cell_type":"code","execution_count":null,"id":"299f894c","metadata":{"id":"299f894c"},"outputs":[],"source":["# CNN Encoder for each frame\n","cnn_encoder = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(256, activation='relu')\n","])\n","\n","# Apply encoder to each frame\n","time_steps = 5\n","encoded_inputs = layers.TimeDistributed(cnn_encoder)(Input(shape=(time_steps, 64, 64, 1)))\n","\n","# LSTM Decoder\n","lstm = layers.LSTM(256, return_sequences=True)(encoded_inputs)\n","decoded = layers.TimeDistributed(layers.Dense(64*64, activation='sigmoid'))(lstm)\n","decoded = layers.TimeDistributed(layers.Reshape((64, 64, 1)))(decoded)\n","\n","model = models.Model(inputs=encoded_inputs._keras_history[0].input, outputs=decoded)\n","model.compile(optimizer='adam', loss='mse')\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"139685be","metadata":{"id":"139685be"},"outputs":[],"source":["model.fit(X_seq, y_seq, epochs=100, verbose=1)"]},{"cell_type":"code","execution_count":null,"id":"4c7ffcea","metadata":{"id":"4c7ffcea"},"outputs":[],"source":["pred_seq = model.predict(X_seq)\n","\n","for i in range(5):\n","    plt.subplot(2, 5, i + 1)\n","    plt.imshow(y_seq[0, i, ..., 0], cmap='gray')\n","    plt.axis('off')\n","    plt.title('GT')\n","\n","    plt.subplot(2, 5, i + 6)\n","    plt.imshow(pred_seq[0, i, ..., 0], cmap='gray')\n","    plt.axis('off')\n","    plt.title('Pred')\n","\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}